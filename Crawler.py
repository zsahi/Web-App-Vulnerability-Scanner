import requests
from bs4 import BeautifulSoup
from core.CoreClasses import Url
from core.CoreClasses import EForm
import Config
from url_normalize import url_normalize
from core import CommonFunctions
from urllib.parse import urlparse
from urllib.parse import urljoin
import math
import multiprocessing

class Crawler:
    uEndPoints = []
    fEndpoints = []
    loginFormEndpoints = []
    urls = []

    def __init__(self):
        pass

    def init(self, url):
        self.urls = []
        self.uEndPoints = []
        self.fEndpoints = []
        self.loginFormEndpoints = []

        url = CommonFunctions.prepend_scheme(url)

        headers = {'User-Agent': Config.user_agent}
        try:
            r = requests.get(url, allow_redirects=True, headers=headers,
                             proxies={"http": Config.http_proxy, "https": Config.https_proxy}, verify=False, timeout=Config.timeout)
        except requests.exceptions.RequestException as e:
            return False

        if r.status_code != 200:
            return False

        url = r.url

        self.urls.append(Url(url, "fresh"))
        self.initial_url = url
        self.parsed_uri = urlparse(url)
        self.origin = '{uri.scheme}://{uri.netloc}'.format(uri=self.parsed_uri)
        self.domain = self.parsed_uri.netloc
        self.scheme = self.parsed_uri.scheme

        return True

    def append_url(self, url):
        flag = False
        for u in self.urls:
            if u.url == url:
                flag = True
                break
        if flag == False:
            self.urls.append(Url(url, "fresh"))
            self.uEndPoints.append(Url(url, "fresh"))

    def append_urls(self, urls):
        if urls is None:
            return
        for url in urls:
            flag = False
            for u in self.urls:
                if u.url == url:
                    flag = True
                    break
            if flag == False:
                self.urls.append(Url(url, "fresh"))
                self.uEndPoints.append(Url(url, "fresh"))

    def get_url_with_status(self, status):
        for u in self.urls:
            if u.status == status:
                return u.url
        return None

    def set_url_status(self, url, status):
        for u in self.urls:
            if u.url == url:
                u.status = status

    def findLoginPanel_thread(self, pages):
        for page in pages:
            url = urljoin(self.origin , page)

            headers = {'User-Agent': Config.user_agent}
            try:
                r = requests.get(url, headers=headers, allow_redirects=True,
                             proxies={"http": Config.http_proxy, "https": Config.https_proxy}, verify=False,stream=True, timeout=Config.timeout)
                if "Content-Length" in r.headers and int(r.headers.get('Content-Length')) > Config.max_response_size:
                    continue
            except requests.exceptions.RequestException as e:
                continue

            if r.status_code != 200:
                continue
            old_url = url
            new_url = r.url

            soup = BeautifulSoup(r.content.decode('utf-8', errors='ignore'), "html.parser")

            for form in soup.findAll("form"):
                if not form.has_attr("action"):
                    continue
                form_action = form.get("action")

                if (form_action is None) or form_action.startswith("#"):
                    form_action = new_url

                elif form_action.startswith('//'):
                    form_action = form_action.replace('//', self.parsed_uri.scheme)

                form_action = urljoin(new_url, form_action)

                method = form.get("method")
                if method == None:
                    method = "Get"
                enctype = form.get("enctype")
                if enctype == None:
                    enctype = "application/x-www-form-urlencoded"

                fields, isLoginForm, refetch_form = CommonFunctions.extract_form_fields(form)
                if isLoginForm :
                    self.append_login_form(EForm(form_action, method, enctype, fields,old_url, refetch_form))

                #self.append_form(EForm(form_action, method, enctype, fields, old_url, refetch_form))
        return self.loginFormEndpoints


    def findLoginPanel(self):
        total_pages = len(Config.loginPages)
        pages_for_single_thread = math.ceil(total_pages/Config.number_of_threads)
        pages = []
        for i in range(0,Config.number_of_threads-1):
            s = i*pages_for_single_thread
            e = ((i+1)*pages_for_single_thread)
            pages.append(Config.loginPages[s:e])

        s = (Config.number_of_threads - 1) * pages_for_single_thread # to cover boundry condition
        pages.append(Config.loginPages[s:])
        pool = multiprocessing.Pool(processes=Config.number_of_threads)
        ret = pool.map(self.findLoginPanel_thread, pages)
        pool.close()
        pool.join()
        for r in ret:
            if len(r)!=0:
                self.loginFormEndpoints.extend(r)

    def crawl(self):
        a = 1
        while True:
            if a > Config.crawl_pages:
                break
            a = a + 1
            url = self.get_url_with_status("fresh")
            if url is None:
                break
            if "setup" in url:
                self.set_url_status(url, "crawled")
                continue
            links = self.crawl_url(url)
            self.append_urls(links)
            self.set_url_status(url, "crawled")


    def append_form(self, eForm):
        if eForm is None or len(eForm.params) == 0:
            return
        if len(self.fEndpoints) == 0:
            self.fEndpoints.append(eForm)
            return

        for f in self.fEndpoints:
            result = CommonFunctions.forms_equal(f, eForm)
            if result == True:
                return
        self.fEndpoints.append(eForm)

    def append_login_form(self, eForm):
        if eForm is None or len(eForm.params) == 0:
            return
        if len(self.loginFormEndpoints) == 0:
            self.loginFormEndpoints.append(eForm)
            return

        for f in self.loginFormEndpoints:
            result = CommonFunctions.forms_equal(f, eForm)
            if result == True:
                return
        self.loginFormEndpoints.append(eForm)

    def crawl_url(self, url):
        results = set()
        #print("Crawling Url: ",url)
        headers = {'User-Agent': Config.user_agent}
        try:
            r = requests.get(url, headers=headers, allow_redirects=True,
                         proxies={"http": Config.http_proxy, "https": Config.https_proxy}, verify=False,
                             timeout=Config.timeout, stream=True)

            if 'Content-Length' in r.headers and int(r.headers.get('Content-Length')) > Config.max_response_size:
                return

        except :
            return

        if not r.url.startswith(self.origin):
            return
        new_url = r.url
        old_url = url
        try:
            soup = BeautifulSoup(r.content.decode('utf-8', errors='ignore'), "html.parser")
        except:
            return
        for link in soup.find_all(href=True):

            url = link.get('href')
            if url == '' or url.startswith('mailto:') or url.startswith('#') or url.lower().startswith('javascript:'):
                continue
            if url.startswith('//'):
                url = url.replace('//', self.scheme)
            if '#' in url:
                url = url.split('#')[0]
            try:
                url = url_normalize(urljoin(new_url, url))
            except:
                continue

            if url.startswith(self.origin):
                results.add(url)

        for form in soup.findAll("form"):
            if not form.has_attr("action"):
                continue
            form_action = form.get("action")

            if (form_action is None) or form_action.startswith("#"):
                form_action = new_url

            elif form_action.startswith('//'):
                form_action = form_action.replace('//', self.scheme)
            try:
                form_action = url_normalize(urljoin(new_url, form_action))
            except:
                continue

            method = form.get("method")
            if method == None:
                method = "Get"
            enctype = form.get("enctype")
            if enctype == None:
                enctype = "application/x-www-form-urlencoded"

            fields, isLoginForm, refetch_form = CommonFunctions.extract_form_fields(form)
            if isLoginForm and len(fields["dynamic"]) <= 3:

                self.append_login_form(EForm(form_action, method, enctype, fields, old_url, refetch_form))

            self.append_form(EForm(form_action, method, enctype, fields, old_url, refetch_form))

        return results

